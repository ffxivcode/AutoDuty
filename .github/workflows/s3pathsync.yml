name: s3-path-uploader
on:
  pull_request:
    types:
      - closed
jobs:
  workflow:
    if: github.event.pull_request.merged == true
    runs-on: ubuntu-latest
    name: Test changed-files
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: List all files in AutoDuty/Paths folder
        id: list-local-files
        run: |
          find AutoDuty/Paths -type f | sed 's|AutoDuty/Paths/||' > local_files.txt
          echo "Local files:"
          cat local_files.txt
      
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4.0.2
        with:
          aws-access-key-id: ${{ secrets.AWS_KEY }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET }}
          aws-region: us-west-2
          
      - name: List all files in S3 bucket
        id: list-s3-files
        run: |
          aws s3 ls s3://${{ secrets.AWS_BUCKET_NAME }} --recursive | awk '{$1=$2=$3=""; print substr($0,4)}' > s3_files.txt
          echo "S3 files:"
          cat s3_files.txt

      - name: Delete files in S3 bucket not in local folder
        run: |
          comm -23 <(sort s3_files.txt) <(sort local_files.txt) > files_to_delete.txt
          echo "Files to delete:"
          cat files_to_delete.txt
          while IFS= read -r file; do
            aws s3 rm "s3://${{ secrets.AWS_BUCKET_NAME }}/$file"
          done < files_to_delete.txt
          
      - name: Get changed files in the paths folder
        id: changed-files-specific
        uses: tj-actions/changed-files@v45.0.3
        with:
          safe_output: "false"
          quotepath: "false"
          files: AutoDuty/Paths/**
          separator: ","

      - name: Run step if any file(s) in the paths folder change
        if: steps.changed-files-specific.outputs.any_changed == 'true'
        run: |
          echo "One or more files in the paths folder has changed."
          echo "List all the files that have changed: ${{ steps.changed-files-specific.outputs.all_changed_files }}"

      - name: Move changed files to temporary folder
        if: steps.changed-files-specific.outputs.any_changed == 'true'
        run: |
          TEMP_DIR=$RUNNER_TEMP/changed_files
          mkdir -p "$TEMP_DIR"
          echo "TEMP_DIR=$TEMP_DIR" >> $GITHUB_ENV
          echo "Temporary directory created at $TEMP_DIR"
          IFS=',' read -ra files <<< "${{ steps.changed-files-specific.outputs.all_changed_files }}"
          for file in "${files[@]}"; do
            stripped_file=$(echo "$file" | sed 's|AutoDuty/Paths/||')
            dest_dir="$TEMP_DIR/$(dirname "$stripped_file")"
            mkdir -p "$dest_dir"
            echo "Moving $GITHUB_WORKSPACE/$file to $dest_dir/"
            mv "$GITHUB_WORKSPACE/$file" "$dest_dir/"
          done
          echo "Files moved to $TEMP_DIR"
          
      - name: Sync temp folder to S3 bucket
        if: steps.changed-files-specific.outputs.any_changed == 'true'
        run: |
          aws s3 sync "$TEMP_DIR" "s3://${{ secrets.AWS_BUCKET_NAME }}/"
