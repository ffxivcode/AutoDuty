name: checkout paths
on:
  push:
jobs:
  checkout:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout paths folder
        uses: actions/checkout@v4
        with:
          sparse-checkout: 'AutoDuty/Paths'
          sparse-checkout-cone-mode: false
      - name: Move paths folder files to root
        run: |
          ls -lah
          shopt -s dotglob
          mv AutoDuty/Paths/* .
          rm -rf AutoDuty
          ls -lah
      - name: List files and folders
        run: |
          echo "Listing all files and folders in the base workspace directory:"
          ls -la
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4.0.2
        with:
          aws-access-key-id: ${{ secrets.AWS_KEY }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET }}
          aws-region: us-west-2
      - name: Sync Paths to S3
        run: |
          find . -type f | while IFS= read -r file; do
            if aws s3api head-object --bucket "${{ secrets.AWS_BUCKET_NAME }}" --key "$file" >/dev/null 2>&1; then
              s3_etag=$(aws s3api head-object --bucket "${{ secrets.BUCKET_NAME }}" --key "$file" --query ETag --output text | tr -d '"')
              md5_local=$(md5sum "$file" | awk '{ print $1 }')
              if [ "$md5_local" != "$s3_etag" ]; then
                echo "Uploading $file to S3"
                aws s3 cp "$file" "s3://${{ secrets.AWS_BUCKET_NAME }}/$file"
              else
                echo "$file is up to date, skipping upload"
              fi
            else
              echo "$file does not exist in S3, uploading"
              aws s3 cp "$file" "s3://${{ secrets.AWS_BUCKET_NAME }}/$file"
            fi
          done
